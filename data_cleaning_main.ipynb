{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "data_cleaning_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHYjUQgKki15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRkfYP4nO4w3"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Work/data_cleaning') ## change the current directory based on the local system"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDEufhb8hZEQ",
        "outputId": "86a4e8e3-4c6b-4af6-f080-f4d728c93241"
      },
      "source": [
        "!pip install xlsxwriter ## install xlswriter if not installed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/ce/74fd8d638a5b82ea0c6f08a5978f741c2655a38c3d6e82f73a0f084377e6/XlsxWriter-1.4.3-py2.py3-none-any.whl (149kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-1.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEouT7HOmIS",
        "outputId": "836e483d-ecf8-49cc-f6ab-235556fe2469"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import words\n",
        "import nltk.tag, nltk.data\n",
        "import spacy\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from collections import Counter\n",
        "from math import sqrt\n",
        "import datetime as dt\n",
        "import logging\n",
        "import re\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import enum\n",
        "import openpyxl\n",
        "lemm = WordNetLemmatizer()\n",
        "path='en'\n",
        "nlp = spacy.load(path, disable=['parser', 'ner'])\n",
        "stop = stopwords.words('english')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDechdoRj4JQ"
      },
      "source": [
        "## Functions for data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Pi94hfQ5ta"
      },
      "source": [
        "def basicTextProcessing(row):\n",
        "    utterance = str(row[\"utterance\"]).lower()\n",
        "    intent = str(row[\"intent\"])\n",
        "    intent = intent.replace(' ', '')\n",
        "    utterance = utterance.translate(str.maketrans('', '', string.punctuation))\n",
        "    utterance = \" \".join(utterance.split())\n",
        "    row[\"utterance\"] = utterance\n",
        "    row[\"intent\"] = intent\n",
        "    return row\n",
        "\n",
        "\n",
        "def removeStopWords(row):\n",
        "    utterance = row[\"utterance\"]\n",
        "    tokens = nltk.word_tokenize(utterance)\n",
        "    sent = \"\"\n",
        "    for w in tokens:\n",
        "        if re.search('[a-zA-Z]', str(w)) != None and not w.lower() in stop:\n",
        "            sent = sent + \" \" + w.lower()\n",
        "    utterance = sent\n",
        "    row[\"utterance\"] = utterance\n",
        "    return row\n",
        "\n",
        "def get_tokens(utterance):\n",
        "    \n",
        "    tokens = nltk.word_tokenize(utterance)\n",
        "    \n",
        "    return tokens\n",
        "    \n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    \n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return wn.NOUN\n",
        "\n",
        "\n",
        "def lemmatizeTokens(row):\n",
        "    utterance = row[\"utterance\"]\n",
        "    tokens = nltk.word_tokenize(utterance)\n",
        "    sent = \"\"\n",
        "    pos = nltk.pos_tag(tokens)\n",
        "    for num, word in enumerate(pos, start=0):\n",
        "        pos_value = word[1]\n",
        "        word_value = word[0]\n",
        "        pos_word = get_wordnet_pos(pos_value)\n",
        "        lemm_token = lemm.lemmatize(word_value, pos_word)\n",
        "        if lemm_token.endswith(\"ing\"):\n",
        "            word_ing.add(lemm_token)\n",
        "        sent = sent + \" \" + lemm_token\n",
        "    sent = sent.strip()\n",
        "    #sent = \" \".join(sent.split())\n",
        "    utterance = sent\n",
        "    row[\"utterance\"] = utterance\n",
        "    return row\n",
        "\n",
        "\n",
        "def lemmatizeTokens_spacy(raw_data_lemm, ignoreTokenList):\n",
        "    #raw_data_lemm = raw_data.copy()\n",
        "    df_temp = pd.DataFrame()\n",
        "    for value, row in raw_data_lemm.iterrows():\n",
        "        \n",
        "        try:\n",
        "            #biGrams = biGram_DF\n",
        "            #triGrams = triGram_DF\n",
        "            utterance = row[\"utterance\"]\n",
        "            #utterance = \"iservice ??\"\n",
        "    \n",
        "            n = 3\n",
        "            sixgrams = nltk.ngrams(utterance.split(), n)\n",
        "            ignoreWords = set()\n",
        "            for grams in sixgrams:\n",
        "                #print(grams)\n",
        "                bGram_1 = grams[0] + \" \" + grams[1]\n",
        "                bGram_2 = grams[1] + \" \" + grams[2]\n",
        "                \n",
        "                triGram_text = grams[0] + \" \" + grams[1] + \" \" + grams[2]\n",
        "                if triGram_text in ignoreTokenList:\n",
        "                    ignoreWords.add(grams[0])\n",
        "                    ignoreWords.add(grams[1])\n",
        "                    ignoreWords.add(grams[2])\n",
        "                elif bGram_1 in ignoreTokenList:\n",
        "                    ignoreWords.add(grams[0])\n",
        "                    ignoreWords.add(grams[1])\n",
        "                elif bGram_2 in ignoreTokenList:\n",
        "                    ignoreWords.add(grams[1])\n",
        "                    ignoreWords.add(grams[2])\n",
        "    \n",
        "        \n",
        "            doc = nlp(utterance)\n",
        "            sent = \"\"\n",
        "            \n",
        "            for token in doc:\n",
        "                #print(token)\n",
        "                #token = doc[1]\n",
        "                \n",
        "                \n",
        "                if token not in ignoreWords and str(token) not in ignoreTokenList and re.search('[a-zA-Z]', str(token)) != None: #and str(Configurations.GeneralConfig.i_Language) == str(Configurations.Language.English)\n",
        "                    #print(token)\n",
        "                    lemm_token = token.lemma_\n",
        "                else:\n",
        "                    lemm_token = token\n",
        "                #if str(lemm_token).endswith(\"ing\"):\n",
        "                    #word_ing.add(token)\n",
        "                if str(lemm_token) == \"-PRON-\":\n",
        "                    lemm_token = token\n",
        "                sent = sent + \" \" + str(lemm_token)\n",
        "            sent = sent.strip()\n",
        "            #sent = \" \".join(sent.split())\n",
        "            utterance = sent\n",
        "            row[\"utterance\"] = utterance\n",
        "            df_temp = df_temp.append(row)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(utterance)\n",
        "            break\n",
        "        \n",
        "    return df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2T2g3GRgif0"
      },
      "source": [
        "### Clenaning of Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1tuEP8-OmIZ"
      },
      "source": [
        "df_train=pd.read_excel('train_irisdata.xlsx',sheet_name='Train',engine='openpyxl')\n",
        "ignoreTokenList=[loc.lower() for loc in pd.read_csv('ngrams.csv')[\"ngram\"].dropna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnWq21E7bF35"
      },
      "source": [
        "df_train['utterance'] = df_train['utterance'].str.lower()\n",
        "df_train['intent'] = df_train['intent'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFyZF39ZbPab"
      },
      "source": [
        "df_train = df_train.apply(basicTextProcessing, axis = 1)\n",
        "lemmatizeTokens_spacy(df_train, ignoreTokenList)\n",
        "df_train = df_train.apply(removeStopWords, axis = 1)\n",
        "df_train['utterance']=df_train['utterance'].str.split().str[-30:].str.join(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbRup5GgmS8"
      },
      "source": [
        "### Cleaning of Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HMS_ZBFcABf"
      },
      "source": [
        "df_test=pd.read_excel('test_irisdata.xlsx',engine='openpyxl')\n",
        "df_test['utterance'] = df_test['utterance'].str.lower()\n",
        "df_test['intent'] = df_test['intent'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZlD2lH2guZt",
        "outputId": "0e817103-8c90-484f-fe72-c0204ec00d1d"
      },
      "source": [
        "df_test = df_test.apply(basicTextProcessing, axis = 1)\n",
        "lemmatizeTokens_spacy(df_test, ignoreTokenList)\n",
        "df_test = df_test.apply(removeStopWords, axis = 1)\n",
        "df_test['utterance']=df_test['utterance'].str.split().str[-30:].str.join(' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generator raised StopIteration\n",
            "avalog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "itiEVZPSg6w-",
        "outputId": "7e15a260-ab81-43ee-8d3d-2b8236e753eb"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>add new user access functional would</td>\n",
              "      <td>access_management.add_new_users_to_access_func...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>add new user access fid</td>\n",
              "      <td>access_management.add_new_users_to_access_func...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apply access funcional account uams</td>\n",
              "      <td>access_management.apply_access_functional_id_i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apply uams coordinator</td>\n",
              "      <td>access_management.apply_for_uams_coordinator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>approver leave uams</td>\n",
              "      <td>access_management.how_to_perform_delegation_in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3487</th>\n",
              "      <td>zoom installation</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3488</th>\n",
              "      <td>zoom software</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3489</th>\n",
              "      <td>zoom usage</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3490</th>\n",
              "      <td>zoomed browser</td>\n",
              "      <td>computer.zoomed_browser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3491</th>\n",
              "      <td>zoomed fonts ie</td>\n",
              "      <td>computer.zoomed_browser</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3492 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 utterance                                             intent\n",
              "0     add new user access functional would  access_management.add_new_users_to_access_func...\n",
              "1                  add new user access fid  access_management.add_new_users_to_access_func...\n",
              "2      apply access funcional account uams  access_management.apply_access_functional_id_i...\n",
              "3                   apply uams coordinator       access_management.apply_for_uams_coordinator\n",
              "4                      approver leave uams  access_management.how_to_perform_delegation_in...\n",
              "...                                    ...                                                ...\n",
              "3487                     zoom installation                          applications_systems.zoom\n",
              "3488                         zoom software                          applications_systems.zoom\n",
              "3489                            zoom usage                          applications_systems.zoom\n",
              "3490                        zoomed browser                            computer.zoomed_browser\n",
              "3491                       zoomed fonts ie                            computer.zoomed_browser\n",
              "\n",
              "[3492 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9rapBEDg_nP"
      },
      "source": [
        "### Labelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzRJmS6-g7xQ"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le=preprocessing.LabelEncoder()\n",
        "le.fit(df_train['intent'])\n",
        "\n",
        "df_train['intent1']=le.transform(df_train['intent'])\n",
        "mapping=df_train[['intent','intent1']].drop_duplicates().rename(columns={'intent1':'mapping'})\n",
        "\n",
        "df_test=pd.merge(df_test,mapping,on='intent',how='left').rename(columns={'mapping':'intent1'})\n",
        "\n",
        "df_test['intent1']=df_test['intent1'].fillna(0).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "a3sygXAHhHIg",
        "outputId": "c26518a2-15b9-47ed-f1fc-34669181ca4f"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>intent</th>\n",
              "      <th>intent1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>add new user access functional would</td>\n",
              "      <td>access_management.add_new_users_to_access_func...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>add new user access fid</td>\n",
              "      <td>access_management.add_new_users_to_access_func...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apply access funcional account uams</td>\n",
              "      <td>access_management.apply_access_functional_id_i...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apply uams coordinator</td>\n",
              "      <td>access_management.apply_for_uams_coordinator</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>approver leave uams</td>\n",
              "      <td>access_management.how_to_perform_delegation_in...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3487</th>\n",
              "      <td>zoom installation</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3488</th>\n",
              "      <td>zoom software</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3489</th>\n",
              "      <td>zoom usage</td>\n",
              "      <td>applications_systems.zoom</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3490</th>\n",
              "      <td>zoomed browser</td>\n",
              "      <td>computer.zoomed_browser</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3491</th>\n",
              "      <td>zoomed fonts ie</td>\n",
              "      <td>computer.zoomed_browser</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3492 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 utterance  ... intent1\n",
              "0     add new user access functional would  ...       4\n",
              "1                  add new user access fid  ...       4\n",
              "2      apply access funcional account uams  ...       8\n",
              "3                   apply uams coordinator  ...      10\n",
              "4                      approver leave uams  ...      23\n",
              "...                                    ...  ...     ...\n",
              "3487                     zoom installation  ...      76\n",
              "3488                         zoom software  ...      76\n",
              "3489                            zoom usage  ...      76\n",
              "3490                        zoomed browser  ...     217\n",
              "3491                       zoomed fonts ie  ...     217\n",
              "\n",
              "[3492 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8BRSlvNj9KW"
      },
      "source": [
        "## Save the cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QooRweGPhHQC"
      },
      "source": [
        "writer=pd.ExcelWriter('test_iris_fullcleaned.xlsx',engine='xlsxwriter')\n",
        "df_test.to_excel(writer,sheet_name='Test',index=None)\n",
        "mapping.to_excel(writer,sheet_name='Mapping',index=None)\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZjROkF1hMmZ"
      },
      "source": [
        "writer=pd.ExcelWriter('train_iris_fullcleaned.xlsx',engine='xlsxwriter')\n",
        "df_train.to_excel(writer,sheet_name='Train',index=None)\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQJ7gw86jLxM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}