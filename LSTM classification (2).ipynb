{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LSTM classification.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"76ab392896454c22b76a20fe477bc8c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_363350eaebf540fcaafac6fa87663744","IPY_MODEL_680a1ee36daf482fbbe1d04b69f81a0b"],"layout":"IPY_MODEL_526494ed86dd4c8f927c575150102a4f"}},"363350eaebf540fcaafac6fa87663744":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Pandas Apply: 100%","description_tooltip":null,"layout":"IPY_MODEL_366f0da0058149dc928571c22847edba","max":19243,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fce28c43eaf4423f9d0b3d9e164da6e3","value":19243}},"680a1ee36daf482fbbe1d04b69f81a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8d6563c1bfe4b478d9fce0c116464a3","placeholder":"​","style":"IPY_MODEL_327a18a94c7f4bcc84043d686b2380f6","value":" 19243/19243 [00:00&lt;00:00, 45865.09it/s]"}},"526494ed86dd4c8f927c575150102a4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"366f0da0058149dc928571c22847edba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fce28c43eaf4423f9d0b3d9e164da6e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d8d6563c1bfe4b478d9fce0c116464a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"327a18a94c7f4bcc84043d686b2380f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c082d33254e44569ce4d55742dd5fac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bc153abe84242008b3c85c9422eb09f","IPY_MODEL_c59a55e916de4f16ac452e82674904ea"],"layout":"IPY_MODEL_053e47ab5ce94ea892a7d7bd651e3c73"}},"0bc153abe84242008b3c85c9422eb09f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Pandas Apply: 100%","description_tooltip":null,"layout":"IPY_MODEL_f0331bd29d0c417db54d71610d132af2","max":19243,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f5493cabac7416fba43f6f49007ded2","value":19243}},"c59a55e916de4f16ac452e82674904ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968ad913331748f3be543f44ec552997","placeholder":"​","style":"IPY_MODEL_db2fa83db5564d51be714aa6715eb99d","value":" 19243/19243 [00:09&lt;00:00, 1994.47it/s]"}},"053e47ab5ce94ea892a7d7bd651e3c73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0331bd29d0c417db54d71610d132af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f5493cabac7416fba43f6f49007ded2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"968ad913331748f3be543f44ec552997":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db2fa83db5564d51be714aa6715eb99d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"UaiSYVbrTXbq"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35gDxPsaUgTx"},"source":["## Import libraries and read data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"CTOU0CEBgpDj","executionInfo":{"status":"error","timestamp":1613453166660,"user_tz":-480,"elapsed":851,"user":{"displayName":"Dhanapal M","photoUrl":"","userId":"14519107343487747203"}},"outputId":"d718e448-81c1-4a2a-ac86-5108a77af5d5"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive') # mound the google drive\n","os.chdir('/content/drive/MyDrive/Dan')\n","\n","\n","!pip install jovian\n","!pip install swifter\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","#library imports\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","from textblob import TextBlob\n","import re\n","import spacy\n","import jovian\n","from collections import Counter\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import string\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from sklearn.metrics import mean_squared_error\n","from sklearn.feature_extraction.text import CountVectorizer\n","import nltk \n","import string\n","import re\n","import swifter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9f23c8faaaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mound the google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dan'"]}]},{"cell_type":"markdown","metadata":{"id":"SuSuDLKZUpYd"},"source":["## Data Cleaning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["76ab392896454c22b76a20fe477bc8c5","363350eaebf540fcaafac6fa87663744","680a1ee36daf482fbbe1d04b69f81a0b","526494ed86dd4c8f927c575150102a4f","366f0da0058149dc928571c22847edba","fce28c43eaf4423f9d0b3d9e164da6e3","d8d6563c1bfe4b478d9fce0c116464a3","327a18a94c7f4bcc84043d686b2380f6","9c082d33254e44569ce4d55742dd5fac","0bc153abe84242008b3c85c9422eb09f","c59a55e916de4f16ac452e82674904ea","053e47ab5ce94ea892a7d7bd651e3c73","f0331bd29d0c417db54d71610d132af2","3f5493cabac7416fba43f6f49007ded2","968ad913331748f3be543f44ec552997","db2fa83db5564d51be714aa6715eb99d"]},"id":"_EpQw4uSgeue","executionInfo":{"elapsed":2016,"status":"ok","timestamp":1613016568060,"user":{"displayName":"Dhanapal M","photoUrl":"","userId":"14519107343487747203"},"user_tz":-480},"outputId":"2208f2bc-4214-4914-cb60-253ea43ced97"},"source":["def remove_punct(text):\n","    text  = \"\".join([char for char in text if char not in string.punctuation])\n","    text = re.sub('[0-9]+', '', text)\n","    return text\n","\n","stopword = nltk.corpus.stopwords.words('english')\n","\n","def remove_stopwords(text):\n","    text = [word for word in re.split('\\W+', text) if word not in stopword]\n","    return text\n","\n","ps = nltk.PorterStemmer()\n","\n","def stemming(text):\n","    text = [ps.stem(word) for word in text]\n","    return text\n","\n","wn = nltk.WordNetLemmatizer()\n","\n","def lemmatizer(text):\n","    text = [wn.lemmatize(word) for word in text]\n","    return ' '.join(text)\n","\n","def spell_correction(text):           # spelling correction\n","    txt=TextBlob(text)\n","    return txt.correct()\n","\n","def clean_data(x):\n","    x=x.encode('ascii','ignore').decode() # remove texts other than english\n","    x=re.sub('https*\\S+','',x) # remove urls\n","    #x=spell_correction(x)\n","    x=remove_punct(x) # remove punctuations\n","    x=remove_stopwords(x) # remove stopwords\n","    #x=stemming(x) # stemming\n","    #x=lemmatizer(x) # lemmatization\n","    return ' '.join(x)\n","\n","data=pd.read_excel('RNN-Data_2.xlsx',sheet_name=None)\n","df_train=data['train data'].rename(columns={'utterance':'text','intent':'label'})[['text','label']]\n","#df_test=pd.read_excel('Unseen - IRIS.xlsx').rename(columns={'input_conversation':'text','Corrected Intent':'label'})[['text','label']]\n","df_test=pd.read_excel('Unseen data - HIRI.xlsx').rename(columns={'Intent':'text','Input Conversation':'label'})[['text','label']]\n","#df_test=pd.read_excel('GoldenCopyDataFile - IRIS.xlsx').rename(columns={'utterance':'text','intent':'label'})[['text','label']]\n","#df_test=data['test data'].rename(columns={'input_conversation':'text','Corrected Intent':'label'})[['text','label']]\n","df_test=df_test[df_test['label'].isin(df_train['label'])]\n","df_train['text']=df_train['text'].swifter.apply(lambda x: clean_data(x))\n","df_test['text']=df_test['text'].swifter.apply(lambda x: clean_data(x))\n","df_train['text_length'] = df_train['text'].swifter.apply(lambda x: len(x.split()))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76ab392896454c22b76a20fe477bc8c5","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=19243.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c082d33254e44569ce4d55742dd5fac","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=19243.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E6mTu1UyBOMX"},"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(df_train['label'])\n","df_train['label']=le.transform(df_train['label'])\n","df_test['label']=df_test['label']=le.transform(df_test['label'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBDZNBTHUyFM"},"source":["## Build the vocabulary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"TNMHwIX5geue","executionInfo":{"elapsed":4729,"status":"ok","timestamp":1613016581517,"user":{"displayName":"Dhanapal M","photoUrl":"","userId":"14519107343487747203"},"user_tz":-480},"outputId":"e9815515-b7b8-49bf-a01e-887a68df3115"},"source":["#tokenization\n","reviews=df_train.text\n","tok = spacy.load('en')\n","def tokenize (text):\n","    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n","    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n","    nopunct = regex.sub(\" \", text.lower())\n","    return [token.text for token in tok.tokenizer(nopunct)]\n","\n","from collections import Counter\n","counts = Counter()\n","for index, row in df_train.iterrows():\n","    counts.update(tokenize(row['text']))\n","#deleting infrequent words\n","print(\"num_words before:\",len(counts.keys()))\n","for word in list(counts):\n","    if counts[word] < 2:\n","        del counts[word]\n","print(\"num_words after:\",len(counts.keys()))\n","#creating vocabulary\n","vocab2index = {\"\":0, \"UNK\":1}\n","words = [\"\", \"UNK\"]\n","for word in counts:\n","    vocab2index[word] = len(words)\n","    words.append(word)\n","def encode_sentence(text, vocab2index, N=10):\n","    tokenized = tokenize(text)\n","    encoded = np.zeros(N, dtype=int)\n","    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n","    length = min(N, len(enc1))\n","    encoded[:length] = enc1[:length]\n","    return encoded, length\n","df_train['encoded'] = df_train['text'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n","df_test['encoded'] = df_test['text'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n","\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["num_words before: 3719\n","num_words after: 2208\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>text_length</th>\n","      <th>encoded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>external storage</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>[[2, 3, 4, 0, 0, 0, 0, 0, 0, 0], 3]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>z file opener</td>\n","      <td>117</td>\n","      <td>3</td>\n","      <td>[[5, 6, 1, 0, 0, 0, 0, 0, 0, 0], 3]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How check Bank locked</td>\n","      <td>25</td>\n","      <td>4</td>\n","      <td>[[7, 8, 9, 10, 0, 0, 0, 0, 0, 0], 4]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>msg file opened another program outlook</td>\n","      <td>296</td>\n","      <td>6</td>\n","      <td>[[11, 6, 12, 13, 14, 15, 0, 0, 0, 0], 6]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>msg file opened Outlook</td>\n","      <td>296</td>\n","      <td>4</td>\n","      <td>[[11, 6, 12, 15, 0, 0, 0, 0, 0, 0], 4]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      text  ...                                   encoded\n","0                         external storage  ...       [[2, 3, 4, 0, 0, 0, 0, 0, 0, 0], 3]\n","1                            z file opener  ...       [[5, 6, 1, 0, 0, 0, 0, 0, 0, 0], 3]\n","2                    How check Bank locked  ...      [[7, 8, 9, 10, 0, 0, 0, 0, 0, 0], 4]\n","3  msg file opened another program outlook  ...  [[11, 6, 12, 13, 14, 15, 0, 0, 0, 0], 6]\n","4                  msg file opened Outlook  ...    [[11, 6, 12, 15, 0, 0, 0, 0, 0, 0], 4]\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"9VGQRpswU4AM"},"source":["## Build pytorch dataset and training and validataion functions."]},{"cell_type":"code","metadata":{"id":"Ry5yqGmmgeui"},"source":["X = list(df_train['encoded'])\n","y = list(df_train['label'])\n","from sklearn.model_selection import train_test_split\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n","\n","class ReviewsDataset(Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]\n","\n","train_ds = ReviewsDataset(X_train, y_train)\n","valid_ds = ReviewsDataset(X_valid, y_valid)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def train_model(model, epochs=10, lr=0.001):\n","    parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    optimizer = torch.optim.Adam(parameters, lr=lr) ### Adam optimizer\n","    for i in range(epochs):\n","        model.train()\n","        sum_loss = 0.0\n","        total = 0\n","        for x, y, l in train_dl:\n","            x = x.long().to(device)\n","            y = y.long().to(device)\n","            y_pred = model(x, l)\n","            optimizer.zero_grad()\n","            loss = F.cross_entropy(y_pred, y) # cross entropy loss\n","            loss.backward()\n","            optimizer.step()\n","            sum_loss += loss.item()*y.shape[0]\n","            total += y.shape[0]\n","        val_loss, val_acc = validation_metrics(model, val_dl)\n","        if i%5==0:\n","          print(\"train loss %.3f, test loss %.3f, test accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n","\n","def validation_metrics (model, valid_dl):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    sum_loss = 0.0\n","    sum_rmse = 0.0\n","    for x, y, l in valid_dl:\n","        x = x.long().to(device)\n","        y = y.long().to(device)\n","        y_hat = model(x, l)\n","        loss = F.cross_entropy(y_hat, y)\n","        pred = torch.max(y_hat, 1)[1]\n","        correct += (pred == y).float().sum()\n","        total += y.shape[0]\n","        sum_loss += loss.item()*y.shape[0]\n","        #sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n","    return sum_loss/total, correct/total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdJ8LstJJ8aY"},"source":["batch_size = 1000\n","vocab_size = len(words)\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","val_dl = DataLoader(valid_ds, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ERwwAAaVAhP"},"source":["## Bidirectional LSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vesN1tGwgeuj","executionInfo":{"elapsed":46083,"status":"ok","timestamp":1613016637830,"user":{"displayName":"Dhanapal M","photoUrl":"","userId":"14519107343487747203"},"user_tz":-480},"outputId":"ca3ed2b1-81d9-4c8a-ce8d-7168eea0a8f6"},"source":["class LSTM_fixed_len(torch.nn.Module) :\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n","        super().__init__()\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True) # activation is taken as tanh\n","        self.linear = nn.Linear(hidden_dim, 465)\n","        self.dropout = nn.Dropout(0.2)\n","        \n","    def forward(self, x, l):\n","        x = self.embeddings(x)\n","        x = self.dropout(x)\n","        lstm_out, (ht, ct) = self.lstm(x)\n","        return self.linear(ht[-1])\n","\n","model = LSTM_fixed_len(vocab_size, 50, 500)\n","model.to(device)\n","train_model(model, epochs=100, lr=0.01)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train loss 6.091, test loss 5.655, test accuracy 0.038\n","train loss 1.482, test loss 1.236, test accuracy 0.707\n","train loss 0.259, test loss 0.718, test accuracy 0.839\n","train loss 0.128, test loss 0.678, test accuracy 0.858\n","train loss 0.089, test loss 0.636, test accuracy 0.866\n","train loss 0.075, test loss 0.631, test accuracy 0.870\n","train loss 0.063, test loss 0.675, test accuracy 0.867\n","train loss 0.061, test loss 0.686, test accuracy 0.870\n","train loss 0.060, test loss 0.698, test accuracy 0.868\n","train loss 0.050, test loss 0.668, test accuracy 0.874\n","train loss 0.055, test loss 0.669, test accuracy 0.873\n","train loss 0.051, test loss 0.701, test accuracy 0.873\n","train loss 0.052, test loss 0.688, test accuracy 0.878\n","train loss 0.040, test loss 0.701, test accuracy 0.876\n","train loss 0.045, test loss 0.741, test accuracy 0.874\n","train loss 0.045, test loss 0.714, test accuracy 0.878\n","train loss 0.046, test loss 0.699, test accuracy 0.881\n","train loss 0.044, test loss 0.695, test accuracy 0.882\n","train loss 0.044, test loss 0.682, test accuracy 0.881\n","train loss 0.052, test loss 0.722, test accuracy 0.881\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LhZpbFBlVS_1"},"source":["## Glove pretrained embedding vector"]},{"cell_type":"code","metadata":{"id":"KZmF1nu-TmGl"},"source":["#!wget http://nlp.stanford.edu/data/glove.6B.zip\n","#!unzip glove*.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CC0aoPMFgeuo"},"source":["# def load_glove_vectors(glove_file=\"./glove.6B.50d.txt\"):\n","#     \"\"\"Load the glove word vectors\"\"\"\n","#     word_vectors = {}\n","#     with open(glove_file) as f:\n","#         for line in f:\n","#             split = line.split()\n","#             word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n","#     return word_vectors\n","\n","# def get_emb_matrix(pretrained, word_counts, emb_size = 50):\n","#     \"\"\" Creates embedding matrix from word vectors\"\"\"\n","#     vocab_size = len(word_counts) + 2\n","#     vocab_to_idx = {}\n","#     vocab = [\"\", \"UNK\"]\n","#     W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n","#     W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n","#     W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n","#     vocab_to_idx[\"UNK\"] = 1\n","#     i = 2\n","#     for word in word_counts:\n","#         if word in word_vecs:\n","#             W[i] = word_vecs[word]\n","#         else:\n","#             W[i] = np.random.uniform(-0.25,0.25, emb_size)\n","#         vocab_to_idx[word] = i\n","#         vocab.append(word)\n","#         i += 1   \n","#     return W, np.array(vocab), vocab_to_idx\n","# word_vecs = load_glove_vectors()\n","# pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UUC4369jVaBd"},"source":["## Bidirectional LSTM with Glove embedding"]},{"cell_type":"code","metadata":{"id":"xcnG4Gy1geup"},"source":["# class LSTM_glove_vecs(torch.nn.Module) :\n","#     def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n","#         super().__init__()\n","#         self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","#         self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n","#         self.embeddings.weight.requires_grad = False ## freeze embeddings\n","#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n","#         self.linear = nn.Linear(hidden_dim, 465)\n","#         self.dropout = nn.Dropout(0.2)\n","        \n","#     def forward(self, x, l):\n","#         x = self.embeddings(x)\n","#         x = self.dropout(x)\n","#         lstm_out, (ht, ct) = self.lstm(x)\n","#         return self.linear(ht[-1])\n","\n","# model = LSTM_glove_vecs(vocab_size, 50, 500, pretrained_weights)\n","# model.to(device)\n","# train_model(model, epochs=50, lr=0.01)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6K9cHd6MF2yE"},"source":["# GRU with Glove embedding"]},{"cell_type":"code","metadata":{"id":"7Xbmf4EqF18H"},"source":["# class GRU_glove_vecs(torch.nn.Module) :\n","#     def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n","#         super().__init__()\n","#         self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","#         self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n","#         self.embeddings.weight.requires_grad = False ## freeze embeddings\n","#         self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","#         self.linear = nn.Linear(hidden_dim, 465)\n","#         self.dropout = nn.Dropout(0.2)\n","        \n","#     def forward(self, x, l):\n","#         x = self.embeddings(x)\n","#         x = self.dropout(x)\n","#         output, ht = self.gru(x)\n","#         return self.linear(ht[-1])\n","\n","# model = GRU_glove_vecs(vocab_size, 50, 500, pretrained_weights)\n","# train_model(model, epochs=5, lr=0.1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uuMABas_GPFV"},"source":["# Prediction on Test data and calculation of accuracy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"id":"HD7RxuCeGObC","executionInfo":{"elapsed":757,"status":"error","timestamp":1613016644143,"user":{"displayName":"Dhanapal M","photoUrl":"","userId":"14519107343487747203"},"user_tz":-480},"outputId":"895a6f84-f73d-4bfc-fd83-6b8c5c762d4e"},"source":["X_test = list(df_test['encoded'])\n","y_test = list(df_test['label'])\n","\n","test_ds = ReviewsDataset(X_test, y_test)\n","test_dl = DataLoader(test_ds, batch_size=len(X_test))\n","_,test_accuracy=validation_metrics(model,test_dl)\n","test_accuracy=test_accuracy.cpu().detach().numpy().reshape(-1)[0]\n","test_accuracy"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-77ca10992d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReviewsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m# auto_collation without custom batch_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mbatch_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             raise ValueError(\"batch_size should be a positive integer value, \"\n\u001b[0;32m--> 217\u001b[0;31m                              \"but got batch_size={}\".format(batch_size))\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             raise ValueError(\"drop_last should be a boolean value, but got \"\n","\u001b[0;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=0"]}]},{"cell_type":"markdown","metadata":{"id":"3yS-wa99Wdt-"},"source":["# Predictions"]},{"cell_type":"code","metadata":{"id":"sLWpYJaoN07_"},"source":["x,y,l=next(iter(test_dl))\n","x = x.long().to(device)\n","y = y.long().to(device)\n","y_pred = model(x, l)\n","y_pred=y_pred.cpu().detach().numpy()\n","y_pred=np.argmax(y_pred,axis=1)\n","y_pred=le.inverse_transform(y_pred)\n","df_test['Predictions']=y_pred\n","df_test['Label']=le.inverse_transform(y_test)\n","df_test[['text','Label','Predictions']].to_csv('OutputunseenIRIS_out.csv',index=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aAYS1ItmWMkE","outputId":"351cbf48-0ace-41d9-9f48-6c7f0fb0189f"},"source":["X_test"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"]}]}]}