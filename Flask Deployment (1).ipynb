{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Flask Deployment.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOhOvExzHd9rFaoTrQDl/Ns"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fmb_ubJgF6WW","executionInfo":{"status":"ok","timestamp":1614227120367,"user_tz":-330,"elapsed":29036,"user":{"displayName":"bharat bhushan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcX3S2BJK7Bcvr4yB9N8JqhPDzE-u0lVrSU0pQeA=s64","userId":"13761418364707206314"}},"outputId":"a3419920-4575-45d6-b226-e7b0602886a1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install flask-ngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a9ERl44YU1GD"},"source":["## Database Connection"]},{"cell_type":"code","metadata":{"id":"T4IA9htCU3kv"},"source":["# import mysql.connector\n","# mydb = mysql.connector.connect(\n","#   host=\"localhost\",\n","#   user=\"yourusername\",\n","#   password=\"yourpassword\"\n","# )\n","\n","# print(mydb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmK49VEPU0X_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mw9vqhokbRtr","executionInfo":{"status":"ok","timestamp":1614227135087,"user_tz":-330,"elapsed":10465,"user":{"displayName":"bharat bhushan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcX3S2BJK7Bcvr4yB9N8JqhPDzE-u0lVrSU0pQeA=s64","userId":"13761418364707206314"}},"outputId":"7a39a7a7-15cc-474c-a470-ff5bdcb97613"},"source":["import os\n","#os.chdir('/content/drive/MyDrive/Dan/Dan')\n","os.chdir('/content/drive/MyDrive/Work/Dan/Deployment')\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","#library imports\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","from textblob import TextBlob\n","import re\n","import spacy\n","from collections import Counter\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import string\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from sklearn.metrics import mean_squared_error\n","from sklearn.feature_extraction.text import CountVectorizer\n","import nltk \n","import string\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-GIkYXxpbO7T"},"source":["def remove_punct(text):\n","    text  = \"\".join([char for char in text if char not in string.punctuation])\n","    text = re.sub('[0-9]+', '', text)\n","    return text\n","\n","stopword = nltk.corpus.stopwords.words('english')\n","\n","def remove_stopwords(text):\n","    text = [word for word in re.split('\\W+', text) if word not in stopword]\n","    return text\n","\n","ps = nltk.PorterStemmer()\n","\n","def stemming(text):\n","    text = [ps.stem(word) for word in text]\n","    return text\n","\n","wn = nltk.WordNetLemmatizer()\n","\n","def lemmatizer(text):\n","    text = [wn.lemmatize(word) for word in text]\n","    return ' '.join(text)\n","\n","def spell_correction(text):           # spelling correction\n","    txt=TextBlob(text)\n","    return txt.correct()\n","\n","def clean_data(x):\n","    x=x.lower()\n","    x=x.encode('ascii','ignore').decode() # remove texts other than english\n","    x=re.sub('https*\\S+','',x) # remove urls\n","    #x=spell_correction(x)\n","    x=remove_punct(x) # remove punctuations\n","    x=remove_stopwords(x) # remove stopwords\n","    #x=stemming(x) # stemming\n","    #x=lemmatizer(x) # lemmatization\n","    return ' '.join(x)\n","    \n","tok = spacy.load('en')\n","\n","def tokenize (text):\n","    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n","    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n","    nopunct = regex.sub(\" \", text.lower())\n","    return [token.text for token in tok.tokenizer(nopunct)]\n","\n","def encode_sentence(text, vocab2index, N=10):\n","    tokenized = tokenize(text)\n","    encoded = np.zeros(N, dtype=int)\n","    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n","    length = min(N, len(enc1))\n","    encoded[:length] = enc1[:length]\n","    return encoded, length\n","    \n","class ReviewsDataset(Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.y = Y\n","        \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]\n","\n","def prep_data(text):\n","  text=clean_data(text)\n","  text=np.array(encode_sentence(text,vocab2index))\n","  return text\n","\n","class LSTM_fixed_len(torch.nn.Module) :\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n","        super().__init__()\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True) # activation is taken as tanh\n","        self.linear = nn.Linear(hidden_dim, df_train.label.nunique())\n","        self.dropout = nn.Dropout(0.2)\n","        \n","    def forward(self, x, l):\n","        x = self.embeddings(x)\n","        x = self.dropout(x)\n","        lstm_out, (ht, ct) = self.lstm(x)\n","        return self.linear(ht[-1])\n","import pickle\n","with open('model_files/label_encoder.pkl', 'rb') as handle:\n","    le= pickle.load(handle)\n","with open('model_files/labels.pkl', 'rb') as handle:\n","    labels=pickle.load(handle)\n","model = torch.load('model_files/model.pth')\n","\n","with open('model_files/vocab.pkl','rb') as vocab:\n","    vocab2index=pickle.load(vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FiHHVAjQj4F","executionInfo":{"status":"ok","timestamp":1614227184314,"user_tz":-330,"elapsed":27579,"user":{"displayName":"bharat bhushan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcX3S2BJK7Bcvr4yB9N8JqhPDzE-u0lVrSU0pQeA=s64","userId":"13761418364707206314"}},"outputId":"c829c7bc-9bfe-474c-8072-07e265d9fc70"},"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask\n","from string import Template\n","from flask import Flask, render_template, request\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)\n","\n","@app.route('/')\n","def home():\n","\treturn render_template('home.html')\n","\n","@app.route('/predict',methods=['POST'])\n","def predict():\n","  if request.method=='POST':\n","    message = request.form['message']\n","    x=torch.from_numpy(prep_data(message)[0].astype(np.int32)).reshape(1,-1).long().to(device)\n","    pred=le.inverse_transform(np.argmax(model(x,None).cpu().detach().numpy(),axis=1))[0]   \n","    print(pred) \n","  return render_template('result.html',prediction = pred)\n","\n","app.run()"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://e49c486235c3.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [25/Feb/2021 04:26:05] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [25/Feb/2021 04:26:06] \"\u001b[33mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 404 -\n","127.0.0.1 - - [25/Feb/2021 04:26:06] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"},{"output_type":"stream","text":["computer.machine_crash\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [25/Feb/2021 04:26:12] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [25/Feb/2021 04:26:12] \"\u001b[33mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"}]}]}